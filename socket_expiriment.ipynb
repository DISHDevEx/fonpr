{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture stream from fluentbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 20:38:47 WARN Utils: Your hostname, codespaces-16de0b resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
      "23/03/28 20:38:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 20:38:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"StreamingDemo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 20:38:55 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n"
     ]
    }
   ],
   "source": [
    "lines = spark.readStream.format(\"socket\").option(\"host\", \"local\").option(\"port\", 9999).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "words = lines.select(explode(split(lines.value, \" \")).alias(\"word\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DStream that will connect to hostname:port, like localhost:9999\n",
    "ssc.start() \n",
    "ssc.awaitTermination() \n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "logging.info(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess a .gz file to isolate one pods worth of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def gz2df(path):\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        \"\"\"\n",
    "        Convert .gz log files into dataframe\n",
    "        \"\"\"\n",
    "        content = f.read().decode('utf-8').split('\\n')\n",
    "        list_rows = []\n",
    "\n",
    "        for i in range(len(content)-1):\n",
    "            row = content[i].split(' ')\n",
    "            list_rows.append(row)\n",
    "        f.close()\n",
    "\n",
    "    df = pd.DataFrame(list_rows, columns=['log_timestamp', 'data'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_type(x):\n",
    "    idx1 = x.find('\"Type\":') + 8\n",
    "    idx2 = x.find(',', idx1) - 1\n",
    "    rec_type = x[ idx1:idx2 ]\n",
    "\n",
    "    return rec_type\n",
    "\n",
    "def filter_by_rec_type(df, rec_type): \n",
    "    return df[df.rec_type == rec_type]\n",
    "\n",
    "def explode_df(df):\n",
    "    return pd.concat([df.log_timestamp, pd.json_normalize(df.data)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "streamed_data_file = \"./node1.gz\"\n",
    "\n",
    "df = gz2df(streamed_data_file)\n",
    "df['rec_type'] = df.data.apply(get_type)\n",
    "df['data'] = df.data.apply(json.loads)\n",
    "\n",
    "\n",
    "\n",
    "list_of_df_rectypes = {}  \n",
    "\n",
    "for rec_type in df.rec_type.unique():\n",
    "    print(rec_type)\n",
    "    rec_type_df = filter_by_rec_type(df, rec_type)\n",
    "    df_exploded = explode_df(rec_type_df)\n",
    "    list_of_df_rectypes[rec_type]=df_exploded\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df_pod = list_of_df_rectypes[\"Pod\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if(\"open5gs-upf\" in df_pod.PodName.unique()):\n",
    "    print(\"upf data exists\")\n",
    "\n",
    "\n",
    "upf_df = df_pod[df_pod[\"PodName\"]==\"open5gs-upf\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## cleaning up the nans in the dataframe\n",
    "\n",
    "print(upf_df['pod_cpu_usage_total'].isna().sum())\n",
    "print(len(upf_df))\n",
    "\n",
    "upf_df = upf_df.dropna(subset=['pod_cpu_usage_total', 'pod_memory_max_usage' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "##setting the limits and requests\n",
    "limit_cpu = max( upf_df[[\"pod_cpu_usage_total\"]].values.tolist() )\n",
    "request_cpu = np.mean( upf_df[[\"pod_cpu_usage_total\"]].values.tolist() ) \n",
    "\n",
    "limit_memory =   max( upf_df[[\"pod_memory_max_usage\"]].values.tolist() )\n",
    "request_memory = np.mean( upf_df[[\"pod_memory_max_usage\"]].values.tolist() ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "logging.info(f'limit_cpu: {limit_cpu}')\n",
    "logging.info(f'request_cpu: {request_cpu}')\n",
    "logging.info(f'limit_memory: {limit_memory}')\n",
    "logging.info(f'request_memory: {request_memory}')\n",
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
