'''
Class defining the Gymnasium type environment for FONPR agents.
'''

import gymnasium as gym
import pandas as pd
import numpy as np
import logging
import datetime
from gymnasium import spaces, Env
from time import sleep
from typing import Tuple

from advisors import PromClient
from utilities import prom_query_rl_upf_experiment1, ec2_cost_calculator
from action_handler import ActionHandler, get_token


class FONPR_Env(Env):
    
    logging.basicConfig(level=logging.INFO)
    metadata = {"render_modes": []}

    def __init__(self, env_config={'render_mode':None, 'window':15, 'sample_rate':4, 'obs_period':5}) -> None:
        # An observation in this case is generated by Prometheus logs covering the past 15 minutes
        self.window = env_config['window'] # How far back in time does the observation look, in minutes
        self.sample_rate = env_config['sample_rate'] # How many observation samples are collected per minute
        self.samples = self.window * self.sample_rate
        self.obs_period = env_config['obs_period'] # How frequently does a new observation occur, in minutes
        
        # States we are observing consist of "Throughput", "Large instance On", "Small instance On"
        low=np.tile(np.array([0., 0., 0.]), (self.samples,1))
        high=np.tile(np.array([np.inf, 1., 1.]), (self.samples,1))
        
        self.observation_space = spaces.Box(
            low=low, 
            high=high, 
            shape=(self.samples, low.shape[1])
            )

        # We have 3 actions, corresponding to "NOOP", Transition to Large", "Transition to Small"
        self.action_space = spaces.Discrete(3)

        # assert render_mode is None or render_mode in self.metadata["render_modes"]
        self.render_mode = env_config['render_mode']
        
        self.step_counter = 0
        self.large_instance_type = 'm4.xlarge' # Hardcoded to begin
        self.small_instance_type = 't3.medium' # Hardcoded to begin

    def _get_obs(self) -> np.array:
        # Request query from Prometheus
        prom_client_advisor = PromClient("http://10.0.104.52:9090")
        prom_client_advisor.set_queries_by_function(prom_query_rl_upf_experiment1())
        prom_response = prom_client_advisor.run_queries()
        
        # Create dataframe for processing of query data
        df = pd.DataFrame(columns=['DateTime', 'Throughput', self.large_instance_type, self.small_instance_type])
        data_df = pd.DataFrame(prom_response[0][0]['values'])
        df[['DateTime', 'Throughput']] = data_df
        df = df.set_index('DateTime') # Use timestamps for index
        df.index = pd.to_datetime(df.index, unit='s')
        df = df.astype('float32')
        
        df['Throughput'] = df['Throughput'] - df.iloc[0,0] # Normalize all throughput to value at first timestamp
        df = df.interpolate() # Linear interpolation for any missing values
        df = df.resample(f'{int(60/self.sample_rate)}s').mean() # Keep input size consistent
        df = df.interpolate() # Linear interp again for any NaNs created by resample
        
        # Process pod info
        # pods = {} # Can be used for debugging
        for i, pod in enumerate(prom_response[1]):
            
            # isolate node label and timestamps
            node = pod['metric']['node']
            values = pod['values']
            
            # map node to instance-type
            prom_client_advisor.set_queries_by_list(['kube_node_labels{node=\'' + node + '\'}'])
            node_labels = prom_client_advisor.run_queries()
            instance_type = node_labels[0][0]['metric']['label_node_kubernetes_io_instance_type']
            
            # pods[f'pod{i}'] = {'node': node, 'values': values, 'instance_type': instance_type} # Can be used for debugging
            
            # create on-flags for instance type
            df_pod = pd.DataFrame(values, columns=['DateTime', instance_type])
            df_pod = df_pod.set_index('DateTime')
            df_pod.index = pd.to_datetime(df_pod.index, unit='s')
            df_pod = df_pod.astype('float32')
            df.update(df_pod)
            df = df.interpolate()
        
        # Ensure input shape is met
        while len(df) != self.samples:
            df.loc[df.index[0]-datetime.timedelta(seconds=60/self.sample_rate)] = df.loc[df.index[0]] # create new timestamp index and copy first row values
            df = df.sort_index()
        
        df = df.fillna(0) # If instance types have NaNs after interp, assumed off
        
        return df.values

    def _get_info(self) -> dict:
        # Provide information on state, action, and reward?
        return {}
        
    def reset(self, *, seed=None, options=None) -> Tuple[np.array, dict]:
        # We need the following line to seed self.np_random
        super().reset(seed=seed)

        observation = self._get_obs()
        info = self._get_info()

        return observation, info

    def step(self, action) -> Tuple[np.array, float, bool, bool, dict]:
        gh_url="https://github.com/DISHDevEx/napp/blob/agent-sac/napp/open5gs_values/5gSA_no_ues_values_with_nodegroups.yaml"
        dir_name="napp"
        
        if action == 0: # No-Op; do nothing
            logging.info('No action taken for this cycle.')
            pass
        elif action == 1: # Transition to Large instance
            logging.info('Transitioning to Large instance type.')
            hndl = ActionHandler(get_token(), gh_url, dir_name, {"target_pod": "upf", "values": "Large"})
            hndl.fetch_update_push_upf_sizing()
        elif action == 2: # Transition to Small instance
            logging.info('Transitioning to Small instance type.')
            hndl = ActionHandler(get_token(), gh_url, dir_name, {"target_pod": "upf", "values": "Small"})
            hndl.fetch_update_push_upf_sizing()
            
        sleep(self.obs_period * 60) # Sleep for observation period before retrieving next observation
        # sleep(10) # For testing
        
        rxtx_value = 3.33e-9 # Rough estimate of dollars per byte over the network
        li_cost = ec2_cost_calculator(self.large_instance_type) # Cost of large instance in dollars per hour
        si_cost = ec2_cost_calculator(self.small_instance_type) # Cost of small instance in dollars per hour
        
        observation = self._get_obs()
        # reward over window: revenue generated by rx/tx on network ($) - cost of running large instance ($) - cost of running small instance ($)
        reward = rxtx_value * observation[-1, 0] \
            -((li_cost / 60) * (np.sum(observation[:, 1]) / self.samples) * self.window) \
            -((si_cost / 60) * (np.sum(observation[:, 2]) / self.samples) * self.window)
        info = self._get_info()
        
        terminated = False # No terminal state for our environment; continuous
        self.step_counter += 1
        truncated = False # Infinite time horizon; no condition where environment gets reset

        # return observation, reward, terminated, truncated, info
        return observation, reward, terminated, truncated, info

    def render(self):
        ...

    def close(self):
        ...
