{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Step is to preprocess a .gz file to isolate one pods worth of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import json\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gz2df(path):\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        \"\"\"\n",
    "        Convert .gz log files into dataframe\n",
    "        \"\"\"\n",
    "        content = f.read().decode('utf-8').split('\\n')\n",
    "        list_rows = []\n",
    "\n",
    "        for i in range(len(content)-1):\n",
    "            row = content[i].split(' ')\n",
    "            list_rows.append(row)\n",
    "        f.close()\n",
    "\n",
    "    df = pd.DataFrame(list_rows, columns=['log_timestamp', 'data'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_type(x):\n",
    "    idx1 = x.find('\"Type\":') + 8\n",
    "    idx2 = x.find(',', idx1) - 1\n",
    "    rec_type = x[ idx1:idx2 ]\n",
    "\n",
    "    return rec_type\n",
    "\n",
    "def filter_by_rec_type(df, rec_type): \n",
    "    return df[df.rec_type == rec_type]\n",
    "\n",
    "def explode_df(df):\n",
    "    return pd.concat([df.log_timestamp, pd.json_normalize(df.data)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PodNet\n",
      "NodeNet\n",
      "NodeFS\n",
      "Container\n",
      "Pod\n",
      "NodeDiskIO\n",
      "Node\n"
     ]
    }
   ],
   "source": [
    "streamed_data_file = \"./node1.gz\"\n",
    "\n",
    "df = gz2df(streamed_data_file)\n",
    "df['rec_type'] = df.data.apply(get_type)\n",
    "df['data'] = df.data.apply(json.loads)\n",
    "\n",
    "\n",
    "\n",
    "list_of_df_rectypes = {}  \n",
    "\n",
    "for rec_type in df.rec_type.unique():\n",
    "    print(rec_type)\n",
    "    rec_type_df = filter_by_rec_type(df, rec_type)\n",
    "    df_exploded = explode_df(rec_type_df)\n",
    "    list_of_df_rectypes[rec_type]=df_exploded\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pod = list_of_df_rectypes[\"Pod\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kube-proxy' 'open5gs-upf' 'open5gs-mongodb' 'cloudwatch-agent'\n",
      " 'fluent-bit' 'open5gs-webui' 'aws-node' 'open5gs-udm' 'ebs-csi-node'\n",
      " 'ueransim-ues-first-batch' 'open5gs-nrf' nan]\n"
     ]
    }
   ],
   "source": [
    "print(df_pod.PodName.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "upf_df = df_pod[df_pod[\"PodName\"]==\"open5gs-upf\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "## cleaning up the nans in the dataframe\n",
    "\n",
    "print(upf_df['pod_cpu_usage_total'].isna().sum())\n",
    "print(len(upf_df))\n",
    "\n",
    "upf_df = upf_df.dropna(subset=['pod_cpu_usage_total', 'pod_memory_max_usage' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "limit_cpu = max( upf_df[[\"pod_cpu_usage_total\"]].values.tolist() )\n",
    "\n",
    "\n",
    "request_cpu = np.mean( upf_df[[\"pod_cpu_usage_total\"]].values.tolist() ) \n",
    "\n",
    "limit_memory =   max( upf_df[[\"pod_memory_max_usage\"]].values.tolist() )\n",
    "request_memory = np.mean( upf_df[[\"pod_memory_max_usage\"]].values.tolist() ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
